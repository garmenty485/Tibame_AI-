{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOJFyELe7wsG"
      },
      "source": [
        "Please download the following zip file, extract it and put it under your google \n",
        "drive\n",
        "\n",
        "https://tinyurl.com/bsff25hs\n",
        "\n",
        "\n",
        "In this example, we will perform a binary classification for heavy makeup and no-heavy makeup images coming from CelebA.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NApxKm8Z69Mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5625239-aa88-489e-9866-bec509a3fc81"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyTXyWEM7IOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127816e2-aaf4-465a-c237-e7082ca99b54"
      },
      "source": [
        "# if you mount Google drive correctly, the following commands should be able to be executed correctly\n",
        "!ls /content/drive/\n",
        "%cd \"/content/drive/My Drive\"\n",
        "% cd \"heavy_makeup_CelebA_s\"\n",
        "\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyDrive  Shareddrives\n",
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/heavy_makeup_CelebA_s\n",
            "train  val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR4O5aWC7qWM"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGAD-b84M67r",
        "outputId": "c10febac-26f8-4abe-c2fb-b45874e6b4bc"
      },
      "source": [
        "# step 1: preparing HOG feature vectors for heavy makeup & no-heavy makeup classification in training & validation, respectively\n",
        "\n",
        "from skimage import data, color, feature\n",
        "import skimage.data\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "import numpy as np\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# image size before cropping\n",
        "resize_img_w = 256\n",
        "resize_img_h = 256\n",
        "\n",
        "# image size after cropping\n",
        "crop_img_w = 224\n",
        "crop_img_h = 224\n",
        "\n",
        "# feature size for 224x224 image using default HOG settings from sklearn\n",
        "HOG_dim = 54756\n",
        "\n",
        "# the folder of training data in YOUR Google drive\n",
        "training_heavy_makeup_imgs_dir = \"/content/drive/My Drive/heavy_makeup_CelebA_s/train/heavy_makeup/\"\n",
        "training_non_heavy_makeup_imgs_dir = \"/content/drive/My Drive/heavy_makeup_CelebA_s/train/no_heavy_makeup/\"\n",
        "\n",
        "# the folder of validation data in YOUR Google drive\n",
        "validation_heavy_makeup_imgs_dir = \"/content/drive/My Drive/heavy_makeup_CelebA_s/val/heavy_makeup/\"\n",
        "validation_non_heavy_makeup_imgs_dir = \"/content/drive/My Drive/heavy_makeup_CelebA_s/val/no_heavy_makeup/\"\n",
        "\n",
        "# the file lists of training data\n",
        "training_heavy_makeup_img_files = glob.glob(training_heavy_makeup_imgs_dir + '*.jpg')\n",
        "training_no_heavy_makeup_img_files = glob.glob(training_non_heavy_makeup_imgs_dir + '*.jpg')\n",
        "\n",
        "# the file lists of validation data\n",
        "validation_heavy_makeup_img_files = glob.glob(validation_heavy_makeup_imgs_dir + '*.jpg')\n",
        "validation_no_heavy_makeup_img_files = glob.glob(validation_non_heavy_makeup_imgs_dir + '*.jpg')\n",
        "\n",
        "# the number of trainimg images: 1000 for postive and negative, respectively\n",
        "training_heavy_makeup_img_file_num = len(training_heavy_makeup_img_files)\n",
        "training_no_heavy_makeup_img_file_num = len(training_no_heavy_makeup_img_files)\n",
        "\n",
        "# the number of validation images: 1000 for postive and negative, respectively\n",
        "validation_heavy_makeup_img_file_num = len(validation_heavy_makeup_img_files)\n",
        "validation_no_heavy_makeup_img_file_num = len(validation_no_heavy_makeup_img_files)\n",
        "\n",
        "\n",
        "#print(len(training_heavy_makeup_img_files))\n",
        "#print(training_no_heavy_makeup_img_files)\n",
        "#print(validation_heavy_makeup_img_files)\n",
        "#print(validation_no_heavy_makeup_img_files)\n",
        "\n",
        "print(\"the number of heavy makeup images in training folder:{} \".format(training_heavy_makeup_img_file_num))\n",
        "print(\"the number of no heavy makeup images in training folder:{} \".format(training_no_heavy_makeup_img_file_num))\n",
        "\n",
        "print(\"the number of heavy makeup images in validation folder:{}\".format(validation_heavy_makeup_img_file_num))\n",
        "print(\"the number of no heavy makeup images in validation folder:{} \".format(validation_no_heavy_makeup_img_file_num))\n",
        "\n",
        "def img_crop(img, resize_img_w, resize_img_h, target_img_w, target_img_h):\n",
        "  #h, w, c =img.shape\n",
        "  img = cv2.resize(img, (int(resize_img_w), int(resize_img_h)))  \n",
        "  top_y = (resize_img_h-target_img_h)/2\n",
        "  btm_y = resize_img_h-(resize_img_h-target_img_h)/2\n",
        "  left_x = (resize_img_w-target_img_w)/2\n",
        "  right_x = resize_img_w-(resize_img_w-target_img_w)/2\n",
        "  cropped_img = img[int(top_y):int(btm_y),int(left_x):int(right_x) ]\n",
        "  \n",
        "  return cropped_img\n",
        "\n",
        "HOG_postitive_matrix = np.zeros([int(training_heavy_makeup_img_file_num), HOG_dim])\n",
        "HOG_negative_matrix = np.zeros([int(training_no_heavy_makeup_img_file_num), HOG_dim])\n",
        "\n",
        "print(\"start to prepare HOG features for postive training images\")\n",
        "start = timer()\n",
        "for i in range(0,int(training_heavy_makeup_img_file_num)):\n",
        "  #print(\"i={}\".format(i))\n",
        "  img = cv2.imread(training_heavy_makeup_img_files[i])\n",
        "  img_cropped = img_crop(img, resize_img_w, resize_img_h, crop_img_w, crop_img_h)\n",
        "  image = cv2.cvtColor(img_cropped, cv2.COLOR_BGR2GRAY)\n",
        "  hog_vec = feature.hog(image)\n",
        "  #print(hog_vec.shape)\n",
        "  HOG_postitive_matrix[i,:] = hog_vec\n",
        "end = timer()\n",
        "print(\"finish preparing HOG features for postive training images and totally {}-seconds are consumed\".format(end-start))\n",
        "\n",
        "\n",
        "print(\"start to prepare HOG features for negative training images\")\n",
        "start = timer()\n",
        "for i in range(0,int(training_no_heavy_makeup_img_file_num)):\n",
        "  #print(\"i={}\".format(i))\n",
        "  img = cv2.imread(training_no_heavy_makeup_img_files[i])\n",
        "  img_cropped = img_crop(img, resize_img_w, resize_img_h, crop_img_w, crop_img_h)\n",
        "  image = cv2.cvtColor(img_cropped, cv2.COLOR_BGR2GRAY)\n",
        "  hog_vec = feature.hog(image)\n",
        "  #print(hog_vec.shape)\n",
        "  HOG_negative_matrix[i,:] = hog_vec\n",
        "end = timer()\n",
        "print(\"finish preparing HOG features for negative training images and totally {}-seconds are consumed\".format(end-start))\n",
        "\n",
        "# stack HOG postive & negative features vertically\n",
        "training_matrix = np.vstack((HOG_postitive_matrix,HOG_negative_matrix))\n",
        "\n",
        "# initialize the label matrix where top half is positive\n",
        "label_matrix = np.zeros(int(training_heavy_makeup_img_file_num) + int(training_no_heavy_makeup_img_file_num))\n",
        "label_matrix[0:int(training_heavy_makeup_img_file_num)] = 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of heavy makeup images in training folder:200 \n",
            "the number of no heavy makeup images in training folder:200 \n",
            "the number of heavy makeup images in validation folder:40\n",
            "the number of no heavy makeup images in validation folder:40 \n",
            "start to prepare HOG features for postive training images\n",
            "finish preparing HOG features for postive training images and totally 6.524903999999879-seconds are consumed\n",
            "start to prepare HOG features for negative training images\n",
            "finish preparing HOG features for negative training images and totally 6.382667414000025-seconds are consumed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CRuj2KOnTwW",
        "outputId": "2d930990-3709-4be0-92f4-b7e7337ebc44"
      },
      "source": [
        "## Optuna is not installed in colab so we need to manually install it.\n",
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.8.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.6.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (5.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.18)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.6.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.4)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.0.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNaCP8fJRv_T"
      },
      "source": [
        "# training and testing function used by Optuna\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "#from sklearn.grid_search import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import optuna\n",
        "\n",
        "def SVM_training_n_testing(trial):\n",
        "    # hyperparameters to be optimized by Optuna in training SVM     \n",
        "    cfg = { 'degree' : trial.suggest_uniform('degree', 0.1, 10), 'C' : trial.suggest_uniform('C', 0.1, 100)}\n",
        "\n",
        "    print(\"start to perform training\")\n",
        "    start = timer()\n",
        "   \n",
        "\n",
        "    ## poly\n",
        "    model = SVC(kernel='poly', probability=True, degree=cfg['degree'], C=cfg['C'])\n",
        "    model.fit(training_matrix, label_matrix)\n",
        "    ##\n",
        "\n",
        "    end = timer()\n",
        "    print(\"training is done and totally {}-seconds are consumed\".format(end-start))\n",
        "\n",
        "    # step 3: accuracy estimation by classifying all the images in the validation folder\n",
        "\n",
        "    # for positive validation data\n",
        "    TP_num = 0\n",
        "    for i in range(0,validation_heavy_makeup_img_file_num): #\n",
        "      img = cv2.imread(validation_heavy_makeup_img_files[i])\n",
        "      img_cropped = img_crop(img, resize_img_w, resize_img_h, crop_img_w, crop_img_h)\n",
        "      image = cv2.cvtColor(img_cropped, cv2.COLOR_BGR2GRAY)\n",
        "      hog_vec = feature.hog(image)\n",
        "      hog_vec = hog_vec.reshape(1,-1)\n",
        "      labels = model.predict(hog_vec)\n",
        "      #print(labels)\n",
        "\n",
        "      if int(labels[0]) == 1:\n",
        "          #print(\"this is TP\")\n",
        "          TP_num = TP_num + 1\n",
        "\n",
        "    print(\"TP_num={}\".format(TP_num))\n",
        "\n",
        "    # for negative validation data\n",
        "    TN_num = 0\n",
        "    for i in range(0,validation_no_heavy_makeup_img_file_num): #\n",
        "      img = cv2.imread(validation_no_heavy_makeup_img_files[i])\n",
        "      img_cropped = img_crop(img, resize_img_w, resize_img_h, crop_img_w, crop_img_h)  \n",
        "      image = cv2.cvtColor(img_cropped, cv2.COLOR_BGR2GRAY)\n",
        "      hog_vec = feature.hog(image)\n",
        "\n",
        "      #print(hog_vec.shape)\n",
        "      hog_vec = hog_vec.reshape(1,-1)\n",
        "      # perform classification\n",
        "      labels = model.predict(hog_vec)\n",
        "      #print(labels)\n",
        "      if int(labels[0]) == 0:\n",
        "        #print(\"this is TP\")\n",
        "        TN_num = TN_num + 1\n",
        "\n",
        "    print(\"TN_num={}\".format(TN_num))\n",
        "    accuracy = (TP_num+TN_num)/(validation_heavy_makeup_img_file_num + validation_no_heavy_makeup_img_file_num)\n",
        "    print(\"accuracy={}\".format(accuracy))\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDar8VxC8G2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ffa5f1-f300-4680-dd94-73da8648b474"
      },
      "source": [
        "# step 2: performing (SVM) classifier training and testing using sklearn\n",
        "\n",
        "sampler = optuna.samplers.TPESampler()      \n",
        "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
        "study.optimize(func=SVM_training_n_testing, n_trials=10)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-01 23:57:51,465]\u001b[0m A new study created in memory with name: no-name-d2cdb9c9-33a6-45be-890f-a935e84a4317\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "start to perform training\n",
            "training is done and totally 66.46260433299994-seconds are consumed\n",
            "TP_num=35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-01 23:59:02,782]\u001b[0m Trial 0 finished with value: 0.825 and parameters: {'degree': 1.4372439781692703, 'C': 75.0667503221738}. Best is trial 0 with value: 0.825.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TN_num=31\n",
            "accuracy=0.825\n",
            "start to perform training\n",
            "training is done and totally 68.89115977900019-seconds are consumed\n",
            "TP_num=36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-02 00:00:16,816]\u001b[0m Trial 1 finished with value: 0.85 and parameters: {'degree': 2.9239468556213097, 'C': 28.223966362317242}. Best is trial 1 with value: 0.85.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TN_num=32\n",
            "accuracy=0.85\n",
            "start to perform training\n",
            "training is done and totally 70.75636533299985-seconds are consumed\n",
            "TP_num=34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-02 00:01:32,872]\u001b[0m Trial 2 finished with value: 0.8 and parameters: {'degree': 4.77269303180191, 'C': 29.322955373296402}. Best is trial 1 with value: 0.85.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TN_num=30\n",
            "accuracy=0.8\n",
            "start to perform training\n",
            "training is done and totally 70.90990822899948-seconds are consumed\n",
            "TP_num=33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-02 00:02:49,151]\u001b[0m Trial 3 finished with value: 0.8125 and parameters: {'degree': 5.1585720767384275, 'C': 72.92051409436228}. Best is trial 1 with value: 0.85.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TN_num=32\n",
            "accuracy=0.8125\n",
            "start to perform training\n",
            "training is done and totally 70.25441670000055-seconds are consumed\n",
            "TP_num=0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-02 00:04:04,757]\u001b[0m Trial 4 finished with value: 0.5 and parameters: {'degree': 0.356805284004159, 'C': 1.366546419443867}. Best is trial 1 with value: 0.85.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TN_num=40\n",
            "accuracy=0.5\n",
            "start to perform training\n",
            "training is done and totally 71.09533503900002-seconds are consumed\n",
            "TP_num=31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-02 00:05:21,301]\u001b[0m Trial 5 finished with value: 0.7875 and parameters: {'degree': 6.703974028376497, 'C': 81.40421419187254}. Best is trial 1 with value: 0.85.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TN_num=32\n",
            "accuracy=0.7875\n",
            "start to perform training\n",
            "training is done and totally 70.1564828419996-seconds are consumed\n",
            "TP_num=37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-02 00:06:36,741]\u001b[0m Trial 6 finished with value: 0.8625 and parameters: {'degree': 3.8118878620436583, 'C': 8.705112719869602}. Best is trial 6 with value: 0.8625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TN_num=32\n",
            "accuracy=0.8625\n",
            "start to perform training\n",
            "training is done and totally 70.83179823799946-seconds are consumed\n",
            "TP_num=34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-02 00:07:52,922]\u001b[0m Trial 7 finished with value: 0.8 and parameters: {'degree': 4.419242094850716, 'C': 74.77386741417952}. Best is trial 6 with value: 0.8625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TN_num=30\n",
            "accuracy=0.8\n",
            "start to perform training\n",
            "training is done and totally 69.72425390100034-seconds are consumed\n",
            "TP_num=40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-02 00:09:08,003]\u001b[0m Trial 8 finished with value: 0.5 and parameters: {'degree': 0.11352086286656904, 'C': 7.011572501104452}. Best is trial 6 with value: 0.8625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TN_num=0\n",
            "accuracy=0.5\n",
            "start to perform training\n",
            "training is done and totally 71.17529613699935-seconds are consumed\n",
            "TP_num=31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-02 00:10:24,622]\u001b[0m Trial 9 finished with value: 0.7875 and parameters: {'degree': 6.427872916350362, 'C': 55.62770926330358}. Best is trial 6 with value: 0.8625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TN_num=32\n",
            "accuracy=0.7875\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}